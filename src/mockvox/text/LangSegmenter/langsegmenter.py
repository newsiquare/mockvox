import logging
import re

# jiebaé™éŸ³
import jieba

jieba.setLogLevel(logging.CRITICAL)

SPECIAL_CHARS = r"0-9ã€œ~,.;:!?ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€Â·([{<ï¼ˆã€ã€Šã€ˆã€Œã€â€œâ€˜)\]}>ï¼‰ã€‘ã€‹ã€‰ã€ã€â€â€™\"-_â€”â€”\#$%&â€¦â€¦ï¿¥'*+<=>?@[\]^_`{|}~ "

from split_lang import LangSplitter


def full_en(text):
    pattern = r"^[A-Za-z0-9\s\u0020-\u007E\u2000-\u206F\u3000-\u303F\uFF00-\uFFEF]+$"
    return bool(re.match(pattern, text))


def full_cjk(text):
    # æ¥è‡ªwiki
    cjk_ranges = [
        (0x4E00, 0x9FFF),  # CJK Unified Ideographs
        (0x3400, 0x4DB5),  # CJK Extension A
        (0x20000, 0x2A6DD),  # CJK Extension B
        (0x2A700, 0x2B73F),  # CJK Extension C
        (0x2B740, 0x2B81F),  # CJK Extension D
        (0x2B820, 0x2CEAF),  # CJK Extension E
        (0x2CEB0, 0x2EBEF),  # CJK Extension F
        (0x30000, 0x3134A),  # CJK Extension G
        (0x31350, 0x323AF),  # CJK Extension H
        (0x2EBF0, 0x2EE5D),  # CJK Extension H
    ]

    pattern = rf"^[{SPECIAL_CHARS}]+$"

    cjk_text = ""
    for char in text:
        code_point = ord(char)
        in_cjk = any(start <= code_point <= end for start, end in cjk_ranges)
        if in_cjk or re.match(pattern, char):
            cjk_text += char
    return cjk_text


def split_jako(tag_lang, item):
    if tag_lang == "ja":
        pattern = rf"([\u3041-\u3096\u3099\u309A\u30A1-\u30FA\u30FC]+(?:[{SPECIAL_CHARS}]+[\u3041-\u3096\u3099\u309A\u30A1-\u30FA\u30FC]*)*)"
    else:
        pattern = rf"([\u1100-\u11FF\u3130-\u318F\uAC00-\uD7AF]+(?:[{SPECIAL_CHARS}]+[\u1100-\u11FF\u3130-\u318F\uAC00-\uD7AF]*)*)"

    lang_list: list[dict] = []
    tag = 0
    for match in re.finditer(pattern, item["text"]):
        if match.start() > tag:
            lang_list.append({"lang": item["lang"], "text": item["text"][tag : match.start()]})

        tag = match.end()
        lang_list.append({"lang": tag_lang, "text": item["text"][match.start() : match.end()]})

    if tag < len(item["text"]):
        lang_list.append({"lang": item["lang"], "text": item["text"][tag : len(item["text"])]})

    return lang_list


def merge_lang(lang_list, item):
    if lang_list and item["lang"] == lang_list[-1]["lang"]:
        lang_list[-1]["text"] += item["text"]
    else:
        lang_list.append(item)
    return lang_list


class LangSegmenter:
    # é»˜è®¤è¿‡æ»¤å™¨, åŸºäºgsvç›®å‰å››ç§è¯­è¨€
    DEFAULT_LANG_MAP = {
        "zh": "zh",
        "yue": "zh",  # ç²¤è¯­
        "wuu": "zh",  # å´è¯­
        "zh-cn": "zh",
        "zh-tw": "x",  # ç¹ä½“è®¾ç½®ä¸ºx
        "ko": "ko",
        "ja": "ja",
        "en": "en",
    }

    def getTexts(text):
        lang_splitter = LangSplitter(lang_map=LangSegmenter.DEFAULT_LANG_MAP)
        substr = lang_splitter.split_by_lang(text=text)

        lang_list: list[dict] = []

        for _, item in enumerate(substr):
            dict_item = {"lang": item.lang, "text": item.text}

            # å¤„ç†çŸ­è‹±æ–‡è¢«è¯†åˆ«ä¸ºå…¶ä»–è¯­è¨€çš„é—®é¢˜
            if full_en(dict_item["text"]):
                dict_item["lang"] = "en"
                lang_list = merge_lang(lang_list, dict_item)
                continue

            # å¤„ç†éæ—¥è¯­å¤¹æ—¥æ–‡çš„é—®é¢˜(ä¸åŒ…å«CJK)
            ja_list: list[dict] = []
            if dict_item["lang"] != "ja":
                ja_list = split_jako("ja", dict_item)

            if not ja_list:
                ja_list.append(dict_item)

            # å¤„ç†ééŸ©è¯­å¤¹éŸ©è¯­çš„é—®é¢˜(ä¸åŒ…å«CJK)
            ko_list: list[dict] = []
            temp_list: list[dict] = []
            for _, ko_item in enumerate(ja_list):
                if ko_item["lang"] != "ko":
                    ko_list = split_jako("ko", ko_item)

                if ko_list:
                    temp_list.extend(ko_list)
                else:
                    temp_list.append(ko_item)

            # æœªå­˜åœ¨éæ—¥éŸ©æ–‡å¤¹æ—¥éŸ©æ–‡
            if len(temp_list) == 1:
                # æœªçŸ¥è¯­è¨€æ£€æŸ¥æ˜¯å¦ä¸ºCJK
                if dict_item["lang"] == "x":
                    cjk_text = full_cjk(dict_item["text"])
                    if cjk_text:
                        dict_item = {"lang": "zh", "text": cjk_text}
                        lang_list = merge_lang(lang_list, dict_item)
                    continue
                else:
                    lang_list = merge_lang(lang_list, dict_item)
                    continue

            # å­˜åœ¨éæ—¥éŸ©æ–‡å¤¹æ—¥éŸ©æ–‡
            for _, temp_item in enumerate(temp_list):
                # æœªçŸ¥è¯­è¨€æ£€æŸ¥æ˜¯å¦ä¸ºCJK
                if temp_item["lang"] == "x":
                    cjk_text = full_cjk(dict_item["text"])
                    if cjk_text:
                        dict_item = {"lang": "zh", "text": cjk_text}
                        lang_list = merge_lang(lang_list, dict_item)
                else:
                    lang_list = merge_lang(lang_list, temp_item)
        return lang_list


if __name__ == "__main__":
    text = "MyGO?,ä½ ä¹Ÿå–œæ¬¢ã¾ã„ã”å—ï¼Ÿ"
    print(LangSegmenter.getTexts(text))

    text = "ã­ãˆã€çŸ¥ã£ã¦ã‚‹ï¼Ÿæœ€è¿‘ã€åƒ•ã¯å¤©æ–‡å­¦ã‚’å‹‰å¼·ã—ã¦ã‚‹ã‚“ã ã€‚å›ã®ç³ãŒæ˜Ÿç©ºã¿ãŸã„ã«ã‚­ãƒ©ã‚­ãƒ©ã—ã¦ã‚‹ã‹ã‚‰ã•ã€‚"
    print(LangSegmenter.getTexts(text))

    text = r"ã“ã‚“ã«ã¡ã¯ì•ˆë…•í•˜ì„¸ìš”ä½ å¥½ï¼ğŸµä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ? ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ" \
             r"12345@#$%^&*()_+-=[]{}\|;:',.<>/?ï¼ï¼Ÿã€ã€‚ã€œï½ã€ã€‘ã€Šã€‹ã€Œã€ã€ã€â€œâ€â€˜â€™Â¥Â£â‚¬ğŸ’µ" \
             r"æ—¥æœ¬èªã¨í•œêµ­ì–´ã¨ä¸­æ–‡ã‚’æ··ãœã¾ã—ãŸï¼í”¼ìé£Ÿã¹ãŸã„? æˆ‘æƒ³åƒæŠ«è¨ğŸ•ï¼âœˆï¸æ—…è¡Œã«è¡Œãã¾ã—ã‚‡ã†~" \
             r"í•œê¸€(éŸ“æ–‡), æ¼¢å­—(æ±‰å­—), ã²ã‚‰ãŒãª(Hiragana) â˜…â˜…â˜…é‡è¦ï¼ï¼"
    print(LangSegmenter.getTexts(text))
    
